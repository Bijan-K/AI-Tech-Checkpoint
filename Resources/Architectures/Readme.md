# Transformers
- [Attention is all you need](https://arxiv.org/abs/1706.03762)
- [Flash attention](https://arxiv.org/abs/2205.14135)


# Diffusion
- [diff-usion's collection](https://github.com/diff-usion/Awesome-Diffusion-Models)

# Mamba
- [Mamba1](https://arxiv.org/abs/2312.00752)
- [Mamba2](https://arxiv.org/abs/2405.21060)
- [Blog](https://tridao.me/blog/2024/mamba2-part1-model/)

# LSTMs
- [xLSTM](https://arxiv.org/abs/2405.04517)