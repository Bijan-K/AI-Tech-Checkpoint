# Code Generation

> Models

- [Claude 3](https://www.anthropic.com/news/claude-3-family)
- [Chatgpt's GPT-4](https://openai.com/research/gpt-4)
- [Code Llama2](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/)
- [Phind](https://www.phind.com/search?home=true)
- [Mixtal-8x7b-instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)
- [Deepseek-coder-33b-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct)

> Editor..ish:

- [Github Copilot](https://github.com/features/copilot)
- [Cursor](https://cursor.sh)
- [Cody](https://sourcegraph.com/cody)
- [Supermaven](https://supermaven.com)
- [Codeium](https://codeium.com)
- [TabNine](https://www.tabnine.com)
- [DevGpt](https://www.devgpt.com)

> full on engineer???

- [Devin](https://x.com/cognition_labs/status/1767548763134964000?s=20)

Update:
...They are also a OpenAI wrapper... lol

---

Welp, I don't think LLMs are suitable for complex logical tasks but who knows what happens with enough scale and honestly OpenAI is not an average company.

Currently LLMs are token-predictors, the best they can do is parrot someone else's logic in the form of text(after a lot of training).
